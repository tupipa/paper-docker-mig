
\subsection{Emerging Applications in Edge Computing}



\subsection{Service Hand-off in Edge Computing Infrastructure}

With the advancement of Internet of Things and Edge Computing, many emerging applications require high bandwidth and low latency of network, which could easily overwhelm the ability of centralized cloud infrastructure. This drives the clouds towards dispersion. For example, in \cite{satya2017edge}, many wearable cognitive assistance applications can offload resource-intensive computing to cloudlet servers and were shown to be able to deliver highly responsive services as well as improved scalability and privacy enforcement ability.  However, there are still lots of challenges before we can really deploy this edge cloud infrastructure. 

One of the biggest challenges is to enable the free mobility for the mobile devices from the edge servers. In the centralized cloud infrastructure, mobility of clients are well guaranteed since the cloud server is always connected through the long latency WAN internet. However, in the edge computing infrastructure, mobile devices are connected to the nearby edge servers within limited network coverage scope. Therefore, when the mobile device moves far away from the edge server, it might be out of service, or alternatively, it has to handoff from the current edge server to a nearer edge server. 

This is very similar to the \textit{seamless hand-off } mechanism in the cellular networks, where the moving client can seamlessly hand-off across base stations and be served by its nearest available station. In cellular networks, changing a base station for a client is just to rebuild a wireless connection. Most of the run-time states of the services are still available either on the client or on the remote server. After re-connection, the run-time state can be quickly resumed seamlessly. 

However, there is one key difference between the cellular network hand-off and edge server hand-off. In the edge infrastructure, most mobile devices are using edge server to offload the resource intensive computing. This means the edge server will hold the states of all those resource intensive workloads. If we mobile hand-off from one edge server to another, just rebuilding the connection is certainly not enough. All the offloaded workloads are also need to be transferred from the current edge server to the next edge server.  

One possible solution might be using the live migration to migrate a virtual machine from on edge server to another in order to seamlessly transfer the offloading workloads. However, researchers in \cite{ha2015vmhandoff} have shown this is not feasible since live migration is originally designed for large data centers with high bandwidth network which is not feasible for edge servers which are deployed on the edge of WANs. Furthermore, live migration relies on shared storage so that it transfers only run-time state and doesn't transfer the disk storage data. Apparently, shared storage across the edge computing infrastructure is not feasible due to its widely distributed and low bandwidth feature. 

In order to enable hand-off across edge computing servers, many researches have been done based on virtual machine techniques. 

% \subsection{Fog/Edge Computing}
% \subsection{Virtual Machine Live Migration}
% \subsection{Cloudlet}

\subsection{Dynamic VM Synthesis and VM Hand-off} \label{motivation:vmhandoff}

% Many researches have been done in order to accelerate the service handoff across edge servers.
Techniques based on virtual machine migration have been proposed in  \cite{ha2015vmhandoff} \cite{satya2009case} to accelerate the service handoff across edge servers. Virtual Machine live migration in data centers could not be used for service handoff, which was well discussed in \cite{ha2015vmhandoff}. Firstly, Live migration of VM requires high bandwidth of connection and transfers Gigabytes of data in each migration, where service handoff for offloading happens on low bandwidth WANs. Secondly, live migration in data centers aims at short duration of the VM down time. However, service handoff across edge servers requires to optimize the time of total operations from the beginning of handoff request. 

In order to enable high speed service hand-off based on virtual machine migration techniques, VM synthesis\ cite{satya2009case}  was first proposed to enable resource-intensive mobile applications to leverage cloud computing under low WAN delays. It divided a huge VM imges into a base VM image and multiple small-sized application-specific overlay images. The server was assumed to have a base image and mobile device could just transfer its application's overlay images to the server. Then the server would run the resource-intensive application on behalf of the resource-limited mobile devices. 


Based on the work of VM synthesis, \cite{ha2015vmhandoff} enabled VM handoff across Couldlet servers (alias of edge servers). It allowed mobile clients seamlessly transfer its offloading workloads from one edge sever to a nearer edge server. Before the migration, it assumed both server already had the base VM image. Therefore, during VM hand-off, only the VM overlay encapsulated the application and its runtime states were transferred through the network. It highly reduced the transfer size and time compared to the solely VM migration. 

However,
% the transfer size of the application still had tens or hundreds of megabytes on average. 
the total hand-off time was still several minutes on a WAN network. For example, it will requires $245.5$ seconds to migrate a running OpenFace instance under 5Mbps bandwidth (50ms latency) network in \cite{ha2015vmhandoff}. 
One of the reasons for the long latency of handoff the large image size we need to transfer. Although the VM synthesis could reduce the image size by splitting images into multiply layers and only transfer the application-specific layer, the total transferred size is still in the magnitude of tens of megabytes and even hundreds of megabytes. 
The application layer was encapsulated with the whole application, both its static binary programs and its runtime memory data, which we think is an unnecessary cost. 

On the other hand, the deployment of the VM synthesis system is challenging for the legacy system. In order to enable VM synthesis, the hypervisor of VMs need to be patched to track the dirty memory at runtime. Also the storage of VM images need to be adapted to Linux FUSE interfaces in order to track file system changes inside the running VMs. Those two changes are hard to deploy in practice since they changes the behavior of hypervisors and file systems of the legacy platform and will also cause lots of performance overhead. 

% \subsection{Latency Sensitive Mobile Applications}

% \subsubsection{Enlightened VM Post-Copy} In order to improve the 
\subsection{Live Migration of Containers}
LXC, 
LXCFS


OpenVZ, distributed file system\cite{openvzfs}. Files are not stored locally, no layerred images.
