
% What is the problem?
% Why is it interesting and important?
Edge computing has attracted lots of attention both from industry and academia in recent years\cite{satya2009case,  MEC2014initiative, MEC2015-5G, yi2015fog,yi2015survey,shi2016edge,chiang2016fog,satya2017edge}.
By placing resource-rich nodes in close proximity to mobile or Internet of Things (IoT) devices, edge computing offers more responsive services, along with higher scalability and availability than traditional cloud platforms \cite{MEC2014initiative,satya2017edge}.
To take advantage of nearby resources, computation offloading techniques have been playing an important role~\cite{cuervo2010maui,lane2016deepx,openface2016,liu2016paradrop}.
%%% here we can cite more offloading papers from the committee.

In edge computing environments, offloading computation to the nearest edge server is key to cutting network latency, and improving the user experience. 
However, when a mobile device moves away from its current offloading server, network latency will increase, significantly deteriorating offloading service performance. Ideally, when the user moves, the edge server offloading service should adapt, and move to the nearest edge server in order to maintain highly responsive service. 
% However, we don't want to add any down time during this procedure.
% --- lele: here commented out 'down time', in order to emphasis the metrics of 'total duration' of the migration in the following.
Therefore, migration of the offloading service or application from the current edge server to an edge server nearer to the user is a vitally important activity in the edge computing infrastructure. 

% Why is it hard? (E.g., why do naive approaches fail?)
% Why hasn't it been solved before? (Or, what's wrong with previous proposed solutions? How does mine differ?)
There are several approaches for migrating offloading services. 
VM handoff \cite{ha2015vmhandoff} has been proposed to accelerate service handoff across offloading edge servers. It divided VM images into two stacked overlays based on Virtual Machine (VM) synthesis \cite{satya2009case} techniques. 
The result is that the mobile device only needs to transfer the VM top application overlay to the target server instead of the whole VM image volume. However, considering that the total transferred size is usually on order of tens or hundreds of megabytes, total handoff time is still relatively long for latency sensitive mobile applications. For example, migrating OpenFace \cite{openface2016}, a face recognition application for wearable devices, will cost up to $247$ seconds on a 5Mbps wide area network (WAN), barely meeting the requirements of a responsive user experience. 
Furthermore, VM image overlays are hard to maintain, and not widely available due to limited support and deployment in the real world.

In contrast, the wide deployment of Docker platforms raises the possibility of high speed offloading service handoff. As a container engine, Docker has gained increasing popularity in industrial cloud platforms. It serves as an composing engine for Linux containers, where an application runs in an isolated environment based on OS-level virtualization.
% Docker's application runs in an isolated container with all its dependencies installed.
Docker's storage driver employs layered images inside containers, enabling fast packaging and shipping of any application as a container. 
Many container platforms, such as OpenVZ\cite{openvz}, LXC\cite{qiu2016evaluating}, and Docker \cite{phaul,boucherPhaul}, either completely, or partially support container migration, but none of them are suitable for the edge computing environment. Migration within the official release of OpenVZ~\cite{phaul} eliminates file system transfer using distributed storage. However, due to the geographically distributed nature of edge nodes, and heterogeneity of edge network devices, it is hard to implement distributed storage over WAN that can meet the latency requirements of edge applications. 
LXC migration~\cite{qiu2016evaluating} and Docker migration~\cite{phaul, boucherPhaul} are based on CRIU\cite{criu}, but need to transfer the whole container file system during the migration, resulting in inefficiency and high network overhead.

In exploring an efficient container migration tailored to edge computing, we focus on reducing the file system transfer size, a technique complementary to previous efforts.
%
Docker's layered storage supports copy-on-write (COW), where all writable application data is encapsulated into one thin layer on top of base image layers.
Thus, we only need to transfer the thin top writable layer from each container during migration. Additionally, the Docker infrastructure relies upon widely available public cloud storage to distribute container images (such as Docker Hub\cite{dockerhub} and many other self-hosted image hubs). 
Therefore, application container base image layers can be downloaded from public cloud storage sources before each migration. We argue that taking advantage of the Docker container layered storage has the potential to reduce file system transfer size. To the best of our knowledge, there is no container migration tool that takes efficiently leverages the layered file system. 




% What are the key components of my approach and results? Also include any specific limitations.
In this paper, we propose to build an efficient service handoff system based on Docker container migration. The system leverages the Docker container's layered file system to support high speed migration of offloading services within the edge computing environment. 
There are several challenges to overcome:

First, we need to understand the details of Docker container image layer management. There is little previous work investigating image management inside Docker. In order to provide a systematic birds-eye-view of Docker storage management, we investigate and summarize the layered images based on AUFS storage driver in \ref{aufsIntroduction}.

Second, we need to take advantage of Docker's layered images to speed up migration of containers. Within AUFS storage, we found that Docker creates a new SHA256 number as local  identification for each image layer downloaded from the cloud. 
As a result, if two Docker hosts download the same image layer from the same storage repository, these layers will have different reference identification numbers. This technique was originally a safety mechanism to avoid image overlapping across Docker hosts\cite{dockerlayer}. 
However, when we migrate a container from one Docker host to another, we must recognize that those image layers with different local identification numbers are actually the same content downloaded from the same storage location. This is necessary to avoid transferring redundant image layers during the container migration.

Third, we need to reduce data transferred during migration by recognizing that this data includes both the file system as well as checkpointed binary memory images. Although the total data size is reduced dramatically by leveraging Docker's layered storage, we still need to reduce the memory image size in order to further reduce total transfer time. 

Lastly, we need to find a way to stringently maintain or reduce user-experienced latency during container migration across different edge servers. User-experienced latency could be sustained, and shorter, than the actual migration time through a well designed migration process strategy. Ideally, our goal is a seamless service handoff wherein users cannot notice that their offloading edge server has been changed.

%
To mitigate these challenges, we propose a framework that enables high speed offloading service handoff based on Docker container migration. By only encapsulating and transferring the thin writable \textit{container layer} and its incremental runtime status, we reduce the total handoff time significantly.
% The contributions of this paper are listed as below:
% In summary, in this paper, we make the following contributions:
We make the following contributions in this paper:
\begin{itemize}
    % \item It analyses the status of current techniques to migrate Docker containers. It evaluates the performance of some state-of-the-art works that could do Docker container migration and expose the problems in it.
    
    \item We have investigated the current status of techniques for Docker container migration. 
    We evaluated the performance of state-of-the-art work, and find that no current work has leveraged the layered storage to improve migration performance.
     
    %  \item It analyses the detailed storage management of Docker containers based on AUFS storage driver. It systematically introduces 
    \item  We have analyzed storage management of Docker based on the AUFS storage driver. 
    % and systematically studied the layer management and images stacking methodology inside the Docker storage.
    Based on our analysis, we propose a novel method which leverages layered storage to speed up container migration.
    
    % \item It proposes a framework that enable service handoff across edge offloading servers with help of the high speed migration of containers leveraging the layered images of Docker platform. The framework ensures low end-to-end latency of resource-intensive cloud offloading while maintaining the high mobility of clients. 
 
     \item We have designed a framework that enables efficient handoff of offloading services across edge servers via high speed migration of containers by leveraging the layered storage on Docker platforms. This framework ensures low end-to-end latency of resource-intensive
    %  cloud 
     offloading services
     while maintaining the high mobility of clients. 
     
    % \item It implemented a prototype of the system and evaluate the handoff performance of containers and response time of offloading applications, like OpenFace, etc. 
    \item We have implemented a prototype of our system and conducted extensive evaluations. We have measured container handoff times
    % and offloading response time 
    on real world product applications. Our evaluation shows that the speed up ratio using our framework is $80\%(56\%)$ under 5Mbps(20Mbps) with 50ms network latency.
    
\end{itemize}

