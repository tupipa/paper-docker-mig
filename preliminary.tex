
In this section, we discuss the background of our work and dive into the inner details of Docker's layered storage system for containers. We will also identify the parts of the file system required to be transferred during migration. 
% Before we start to discuss our design, we need to first introduce some inner details about Docker and how it manages it's layered storage. 

Docker is becoming more and more popular and widely adopted in the industrial world, however, the technical details of layered storage management is still not well-documented. 
To the best of the author's knowledge, we are the first to examine the technical details of the Docker layered storage system, and leverage it to speed up the migration of Docker containers. Our work does not require any change to the Docker software stack.

\input{docker-intro.tex}



\subsection{Docker Container Migration in Practice }\label{migpractice}


\input{figure/table-phaul.tex}

Although there is no official  migration tool for Docker containers yet, many enthusiastic developers have constructed some customized tools for certain versions of Docker platforms. These tools have demonstrated the feasibility of Docker container  migration. For example, the CRIU project \cite{criu} supports migration of Docker-1.9.0-dev, and project \cite{boucherPhaul} 
 extends it to support Docker 1.10-dev. However, both methods simply transfer all the files located under the container's root file system from source server to the target server, where the files are actually composed from all the image layers of the migrated container. The methods just ignore the underlying union mounting of the storage layers.
This behavior would cause severe problems from several aspects:
% \begin{enumerate}[series = tobecont , itemjoin = \quad]
\begin{enumerate}[series = tobecont]
    \item It will corrupt the layered file system inside the container after restoration  on the target server. The tools just transfer the whole file system into one directory on the destination server and mount it as root directory for the container. After restoration on the target host, the container no longer maintains its layered image stacks as on the source node. 
    \item It substantially reduces the efficiency and robustness of migration.
    It will synchronize the whole file system of the Docker container using Linux \textit{rsync} command while the container is still running. First, running \textit{rsync} command on a whole file system would be pretty slow due to the large amount of files.  Second, this can result in file contention when the container process and \textit{rsync} process on the source node attempt to access a same file. Contention will cause synchronization error which can result in migration error or failure. 
\end{enumerate}

To verify our claim, we have tested this tool with experiments to migrate containers through different network connections. Our experiments use one simple container, Busybox, and an application, OpenFace, for edge server offloading.  Busybox is a stripped-down Unix tool in a single executable file. This results in a tiny file system inside the container. OpenFace\cite{openface2016} is an application that dispatches images from mobile devices to the edge server, then executes the facial recognition algorithm on server, and finally sends back a text string with the name of the person. The container has a huge file system, approximately $2$ gigabytes.

Table~\ref{table_samehost} indicates migration could be done within 10 seconds for Busybox, and within 30 seconds for OpenFace. The two nodes are two virtual machines on the same physical host. The network between two virtual hosts has a 1Gbps bandwidth with latency of 0.5 milliseconds which transfers 2.17 GB data within a short time.

Due to the dominance of wireless connections in edge computing networks, we further test their containers migrating  between two physical hosts. We used the same wireless LAN network with bandwidth of 15Mbps and latency of 4ms. Table~\ref{table_wireless} shows that the migration of the Busybox container takes 133.11 seconds with transferred size as small as 152 kilobytes. As for migration of OpenFace, it needs to transfer more than 2 Gigabytes data and  costs about 3200 seconds. 

As we have stated, this poor performance is caused by transferring  the whole file system including all the stacked image layers of the container. This is even worse than a mature VM migration. Migration of VMs could avoid transferring a portion of the file system by sharing the base VM images
    \cite{ha2015vmhandoff}, which will finish the migration within several minutes. 

% This behavior would cause severe problems from several aspects:
% % \begin{enumerate}[series = tobecont , itemjoin = \quad]
% \begin{enumerate}[series = tobecont]
%     \item It will corrupt the layered file system inside the container after restored  on the target server. The tools just transfer the whole file system into one directory on the destination server and mount it as root directory for the container. After restored on the target host, the container no longer maintains its layered image stacks as on the source node. 
%     \item It dramatically reduces the efficiency of migration. The transferring size of migrating a container with its whole file system would just worse than a mature VM migration. Because even migration could avoid transferring the whole file system by sharing the base VM images as shown in \ref{motivation:vmhandoff}. 
% \end{enumerate}
Therefore, we need a new tool to properly migrate the Docker containers, avoiding unnecessary transmission of common image layer stacks.   
This new tool should leverage the layered file systems to  transfer the \textit{container layer} only.

% \subsection{Docker Layered Images }

% As a container engine, Docker is increasingly popular in industrial cloud platform. It serves as an composing engine for Linux containers, where applications are running in an isolated environment based on OS-level virtualization. Docker enables layered storage inside containers, which allows fast packaging and shipping of any application as a lightweight container. Each Docker image references a list of read-only layers that represent filesystem differences. Layers are stacked on top of each other to form a base for a containerâ€™s root filesystem \cite{dockerlayer}. 
% % \cite{https://docs.docker.com/engine/userguide/storagedriver/imagesandcontainers/#images-and-layers}

% When a new container is started, a new, thin, writable layer, called \textit{``container layer''} is created on top of the underlying stack. All changes made to the running container are written to this thin layer. 
% % It greatly simplifies the process of setting environment for any software platform. 

% This layered storage allows fast migration of containers' run-time states without having to transfer the system and application base images. With the cloud storage of container images (like in DockerHub), all the container images are available anywhere across the Internet. Therefore, before any migration starts, any edge server has the chance to download the system and application images as the base images stack for the container to run on. 
% During the migration, we only need to transfer the run-time memory states and the thin container layer on top of the Docker images stack. 


% Apparently, the migration of the Docker containers seems to be a better choice than the virtual machine based approaches we introduced above. The layered storage in Docker infrastructure enlightens a great opportunity for the service hand-off in edge computing. If the migration of containers can be done very fast, we can have the service hand-off built ontop of it to get high speed hand-off.
